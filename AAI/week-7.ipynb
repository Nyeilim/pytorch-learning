{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PyTorch是一个开源的Python机器学习库，基于Torch\n",
    "2. 2017年1月，由Facebook人工智能研究院（FAIR）基于Torch推出了PyTorch。\n",
    "3. PyTorch既可以看作加入了GPU支持的numpy，同时也可以看成一个拥有自动求导功能的强大的深度神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors(张量)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tensors 类似于 NumPy 的 ndarrays \n",
    "2. Tensors 可以使用 GPU 进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5.5, 3,4.5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0194e-38, 9.1837e-39, 4.6837e-39],\n",
      "        [9.9184e-39, 9.0000e-39, 1.0561e-38],\n",
      "        [1.0653e-38, 4.1327e-39, 8.9082e-39],\n",
      "        [9.8265e-39, 9.4592e-39, 1.0561e-38],\n",
      "        [1.0653e-38, 1.0469e-38, 9.5510e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1590, 0.3415, 0.8028],\n",
      "        [0.9350, 0.5723, 0.2788],\n",
      "        [0.8585, 0.6793, 0.5615],\n",
      "        [0.5624, 0.6208, 0.8827],\n",
      "        [0.3424, 0.7919, 0.8383]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8659, -0.1031,  1.4662],\n",
      "        [-1.6050,  0.9235, -0.1446],\n",
      "        [ 1.5106,  1.0902, -1.1567],\n",
      "        [ 1.5199,  1.2600, -0.9743],\n",
      "        [-0.0088,  0.0428,  0.4185]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### rand 与randn\n",
    "1. torch.rand()均匀分布：返回一个张量，包含了从区间[0, 1)的均匀分布中抽取的一组随机数。\n",
    "\n",
    "2. torch.randn()标准正态分布：返回一个张量，包含了从标准正态分布（均值为0，方差为1，即高斯白噪声）中抽取的一组随机数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[-0.7041, -0.7569, -0.2750],\n",
      "        [-0.5326, -1.1885,  0.2100],\n",
      "        [-1.2384,  0.3443,  1.9162],\n",
      "        [ 0.2743, -0.5969, -1.0648],\n",
      "        [-0.8921, -0.2111, -0.3761]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3)      \n",
    "# new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x)    \n",
    "# override dtype!\n",
    "print(x)                                      \n",
    "# result has the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_ones()\n",
    "1. 返回一个与size大小相同的用1填充的张量。\n",
    "2. 默认情况下，返回的Tensor具有与此张量相同的torch.dtype和torch.device。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1348, -0.3846,  0.1106],\n",
      "        [ 0.2997, -0.4207,  1.0678],\n",
      "        [-0.5004,  1.0730,  2.0611],\n",
      "        [ 1.1052,  0.1043, -0.0917],\n",
      "        [-0.6089,  0.7064,  0.2649]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3) #方式 1\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1348, -0.3846,  0.1106],\n",
      "        [ 0.2997, -0.4207,  1.0678],\n",
      "        [-0.5004,  1.0730,  2.0611],\n",
      "        [ 1.1052,  0.1043, -0.0917],\n",
      "        [-0.6089,  0.7064,  0.2649]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y)) #方式 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1348, -0.3846,  0.1106],\n",
      "        [ 0.2997, -0.4207,  1.0678],\n",
      "        [-0.5004,  1.0730,  2.0611],\n",
      "        [ 1.1052,  0.1043, -0.0917],\n",
      "        [-0.6089,  0.7064,  0.2649]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result) # 提供一个输出 tensor 作为参数\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1348, -0.3846,  0.1106],\n",
      "        [ 0.2997, -0.4207,  1.0678],\n",
      "        [-0.5004,  1.0730,  2.0611],\n",
      "        [ 1.1052,  0.1043, -0.0917],\n",
      "        [-0.6089,  0.7064,  0.2649]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)  # in-place\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.view 改变一个 tensor 的大小或者形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes of a Tensor\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4567, 0.4524, 0.8394, 0.7076],\n",
      "        [0.6096, 0.1368, 0.2035, 0.9238],\n",
      "        [0.2937, 0.0267, 0.3833, 0.9110],\n",
      "        [0.8282, 0.6367, 0.1356, 0.6972]])\n",
      "First row: tensor([0.4567, 0.4524, 0.8394, 0.7076])\n",
      "First column: tensor([0.4567, 0.6096, 0.2937, 0.8282])\n",
      "Last column: tensor([0.7076, 0.9238, 0.9110, 0.6972])\n",
      "Last column: tensor([0.7076, 0.9238, 0.9110, 0.6972])\n",
      "tensor([[0.4567, 0.0000, 0.8394, 0.7076],\n",
      "        [0.6096, 0.0000, 0.2035, 0.9238],\n",
      "        [0.2937, 0.0000, 0.3833, 0.9110],\n",
      "        [0.8282, 0.0000, 0.1356, 0.6972]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "print(tensor)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch自动微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 如果将torch.Tensor属性 requires_grad ，表明这个tensor是否是可求导的；设置为 True，则会开始跟踪针对 tensor 的所有操作,默认为False.\n",
    "+ 要停止 tensor 历史记录的跟踪，您可以调用 .detach()，它将其与计算历史记录分离，并防止将来的计算被跟踪。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([2.0,2.0,3],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000001E48B5189E8>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27., 27.],\n",
      "        [27., 27., 27.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = z.mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad) # 梯度 d(out)/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 0.8000, 0.0600])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([1.,2,3],requires_grad=True)\n",
    "b=a**2\n",
    "g=torch.tensor([1.0,0.2,0.01])\n",
    "b.backward(g)\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同的分量有不同的权重，例如三个loss，loss1，loss2，loss3，它们的权重可能是不一样的，可通过它来设置，即\n",
    "dy/dx=0.1*dy1/dx+0.2*dy2/dx+0.01*dy3/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
